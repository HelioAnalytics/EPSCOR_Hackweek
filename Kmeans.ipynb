{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HelioAnalytics/EPSCOR_Hackweek/blob/main/Kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91f157d5-fbc2-4e42-a2d8-6ecc64a5f245",
      "metadata": {
        "id": "91f157d5-fbc2-4e42-a2d8-6ecc64a5f245"
      },
      "source": [
        "This exercise only requires `numpy` and `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7ca6d270-f2a2-4337-8ccf-a10964114c72",
      "metadata": {
        "id": "7ca6d270-f2a2-4337-8ccf-a10964114c72"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e409bb6-d1e3-4786-88e4-d7ec28df5d81",
      "metadata": {
        "id": "1e409bb6-d1e3-4786-88e4-d7ec28df5d81"
      },
      "source": [
        "We define options and load data as we did before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e7725e-769c-41da-8502-a59476b830e0",
      "metadata": {
        "id": "84e7725e-769c-41da-8502-a59476b830e0"
      },
      "outputs": [],
      "source": [
        "nc = 3\n",
        "dat1 = 2*np.random.rand(25,2) + 6\n",
        "dat1[:,0] -= 3\n",
        "dat2 = 2*np.random.rand(25,2) + 1\n",
        "dat3 = np.random.rand(25,2) + 3\n",
        "dat3[:,0] += 4\n",
        "dat = np.concatenate((dat1,dat2,dat3),axis=0)\n",
        "dat = np.concatenate((dat,np.zeros(shape=(dat.shape[0],1))),axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52ce2783-e8d9-40e0-b2ab-938fa68968fb",
      "metadata": {
        "id": "52ce2783-e8d9-40e0-b2ab-938fa68968fb"
      },
      "source": [
        "Now we will define the model. First we define the variable `model` as `Sequential()`. Therefore, operations to `model` will be tied to this. We add an input layer and a dense (fully connected) layer to `model`. TensorFlow now knows (due to the Sequential API) that it goes Input then Dense. We also compile the model telling it what the loss function is (`mse` = mean squared error) and how the weights will be updated - through the optimizer (`sgd` = standard gradient descent)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ef84bd-e786-4850-a6c1-77b779728b4b",
      "metadata": {
        "id": "48ef84bd-e786-4850-a6c1-77b779728b4b"
      },
      "outputs": [],
      "source": [
        "def k_means(dat,nc):\n",
        "    cent = 5*np.random.rand(nc,2) + 2\n",
        "    cent = np.array([[4,4],[4,4.5],[3.9,4.4]])\n",
        "    c1 = dat[dat[:,2]==0,:2]\n",
        "    c2 = dat[dat[:,2]==1,:2]\n",
        "    c3 = dat[dat[:,2]==2,:2]\n",
        "    k = 2\n",
        "    counter = 0\n",
        "    while k > 0:\n",
        "        orig = dat[:,2]\n",
        "        for i in range(dat.shape[0]):\n",
        "            dist = np.zeros(3)\n",
        "            for j in range(3):\n",
        "                dist[j] = np.sqrt(np.sum(np.power(dat[i,:2]-cent[j,:],2)))\n",
        "            dat[i,2] = np.argmin(dist)\n",
        "        c1 = dat[dat[:,2]==0,:2]\n",
        "        c2 = dat[dat[:,2]==1,:2]\n",
        "        c3 = dat[dat[:,2]==2,:2]\n",
        "        cent0 = np.zeros([cent.shape[0],cent.shape[1]],dtype='float32')\n",
        "        cent0[:] = cent[:]\n",
        "        if c1.shape[0] != 0:\n",
        "            cent[0,0] -= np.sum(cent[0,0]-c1[:,0])/c1.shape[0]\n",
        "            cent[0,1] -= np.sum(cent[0,1]-c1[:,1])/c1.shape[0]\n",
        "        if c2.shape[0] != 0:\n",
        "            cent[1,0] -= np.sum(cent[1,0]-c2[:,0])/c2.shape[0]\n",
        "            cent[1,1] -= np.sum(cent[1,1]-c2[:,1])/c2.shape[0]\n",
        "        if c3.shape[0] != 0:\n",
        "            cent[2,0] -= np.sum(cent[2,0]-c3[:,0])/c3.shape[0]\n",
        "            cent[2,1] -= np.sum(cent[2,1]-c3[:,1])/c3.shape[0]\n",
        "        new = np.zeros(len(orig))\n",
        "        for i in range(dat.shape[0]):\n",
        "            dist = np.zeros(3)\n",
        "            for j in range(3):\n",
        "                dist[j] = np.sqrt(np.sum(np.power(dat[i,:2]-cent[j,:],2)))\n",
        "            new[i] = np.argmin(dist)\n",
        "        k = np.sum(np.abs(orig-new))\n",
        "    return c1,c2,c3,cent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a104fa6-3844-4f11-a5b3-2fd19bb0e7f6",
      "metadata": {
        "id": "3a104fa6-3844-4f11-a5b3-2fd19bb0e7f6"
      },
      "source": [
        "Calling `model.fit` will train the model for a given number of epochs and with a specified batch size. There are more parameters to choose (see https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit). `verbose=0` means it won't show anything while it trains. You can see the training process if you change `verbose` to 1 (full output) or 2 (output after each epoch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cd556ca-cd49-48fd-a98e-482423f19ee9",
      "metadata": {
        "id": "3cd556ca-cd49-48fd-a98e-482423f19ee9"
      },
      "outputs": [],
      "source": [
        "c1,c2,c3,cent = k_means(dat,nc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0407444-a374-4fd0-a2fb-45269d945881",
      "metadata": {
        "id": "d0407444-a374-4fd0-a2fb-45269d945881"
      },
      "source": [
        "Here we are just plotting the data and discrimination line as we did before. NOTE: we change how the model is used in the `plot_line` function. Look for the `model.predict` call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab5852c3-7504-48f9-9658-f6dcd0c1446f",
      "metadata": {
        "id": "ab5852c3-7504-48f9-9658-f6dcd0c1446f"
      },
      "outputs": [],
      "source": [
        "fig,ax=plt.subplots()\n",
        "plt.scatter(c1[:,0],c1[:,1],color='blue')\n",
        "plt.scatter(c2[:,0],c2[:,1],color='red')\n",
        "plt.scatter(c3[:,0],c3[:,1],color='green')\n",
        "plt.scatter(cent[0,0],cent[0,1],color='blue',s=400)\n",
        "plt.scatter(cent[1,0],cent[1,1],color='red',s=400)\n",
        "plt.scatter(cent[2,0],cent[2,1],color='green',s=400)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Flower_NN_TF.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}